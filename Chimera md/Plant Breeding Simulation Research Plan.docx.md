# **A Comprehensive Research Plan for Developing Plant Breeding Simulations**

## **Introduction**

Plant breeding stands as a cornerstone in addressing pressing global challenges, including ensuring food security for a growing population, adapting agriculture to a changing climate, and enhancing the nutritional value of crops. Modern plant breeding programs are increasingly complex, data-intensive operations, integrating cutting-edge techniques from genomics, phenomics, data analytics, and biotechnology to achieve targeted genetic improvements. This transformation necessitates sophisticated tools for planning, optimizing, and executing breeding strategies.  
Within this context, plant breeding simulations have emerged as indispensable instruments. They provide a powerful computational framework to bridge the gap between the theoretical principles of quantitative genetics and the practical realities of applied breeding. By replicating biological processes and breeding activities *in silico*, simulations allow researchers and breeders to test hypotheses, rigorously compare the potential outcomes of different breeding methodologies (e.g., phenotypic selection, marker-assisted selection (MAS), genomic selection (GS)), optimize the allocation of limited resources (time, budget, personnel), predict and accelerate genetic gain, and serve as valuable educational platforms. A key advantage is their cost-effectiveness; simulations enable the exploration of numerous complex scenarios that would be prohibitively expensive or time-consuming to evaluate through extensive, multi-year field trials.  
This document presents a comprehensive, step-by-step research plan for the development of robust and informative plant breeding simulations. It details the critical phases involved, from defining clear objectives and identifying necessary data to selecting appropriate models and software, designing the simulation architecture, implementing validation and calibration procedures, anticipating challenges, establishing evaluation metrics, and planning for documentation and dissemination. The plan aims to provide rigorous guidance for researchers embarking on the development of simulation tools capable of accurately mimicking plant breeding processes and generating actionable insights for crop improvement.

## **Section 1: Defining Clear Research Objectives and Goals**

The cornerstone of any successful simulation study is the establishment of clear, unambiguous research objectives and goals. These objectives dictate the necessary scope, complexity, and focus of the simulation model, guiding every subsequent step from parameterization to evaluation. Vague or poorly defined objectives can lead to simulations that are either overly simplistic, failing to capture the essential dynamics needed to answer the research question, or excessively complex, incorporating unnecessary details that inflate computational demands and complicate calibration and interpretation. Therefore, investing time in precisely defining what the simulation aims to achieve is paramount for ensuring the model is both relevant and tractable.  
Plant breeding activities can be broadly categorized based on their primary goals, providing a useful framework for structuring simulation objectives. These categories include:

1. **Genetic Improvement:** Focusing on enhancing the overall genetic merit or structure of the breeding population itself, such as increasing the mean performance for key traits or managing genetic diversity over time.  
2. **Cultivar Development:** Aiming to create specific new varieties with a desired combination of traits that meet predefined product profiles for release.  
3. **Product Placement:** Evaluating or optimizing the performance of specific genotypes or cultivars within defined target populations of environments (TPEs) or management systems.

Tailoring simulation objectives to one or more of these categories helps focus the modeling effort. Specific examples of well-defined objectives for plant breeding simulations include:

* Quantifying the expected rate of genetic gain ({\\Delta}G) for yield and disease resistance under a rapid-cycling genomic selection strategy compared to a traditional pedigree method, given a fixed annual budget.  
* Comparing the efficiency (gain per unit time and cost) of marker-assisted selection versus genomic selection for introgressing a complex, polygenic trait from an exotic donor into an elite line.  
* Evaluating the potential impact of integrating speed breeding technology (reducing cycle time) on long-term genetic gain and genetic diversity in a wheat breeding program.  
* Investigating how different levels of epistasis influence the accuracy of genomic prediction models over multiple cycles of recurrent selection.  
* Simulating Genotype-by-Environment (GxE) interactions across a target population of environments to identify genotypes with broad versus specific adaptation, using a multi-trait or crop model approach.  
* Assessing the long-term consequences of different parent selection strategies (e.g., truncation selection vs. optimal contribution selection) on the maintenance of genetic variance and the frequency of rare alleles.  
* Determining the optimal allocation of resources between the number of individuals phenotyped versus the number of environments or replications used, to maximize prediction accuracy for genomic selection.

It is highly recommended to formulate these objectives using the SMART criteria (Specific, Measurable, Achievable, Relevant, Time-bound). For example, instead of "Investigate GS," a SMART objective might be: "To quantify the increase in genetic gain (Measurable) for grain yield (Specific) achievable by implementing a two-stage genomic selection strategy versus phenotypic selection over 10 breeding cycles (Time-bound) within the existing program budget (Achievable), for a simulated maize breeding program targeting drought-prone environments (Relevant)."  
Crucially, these well-defined objectives directly translate into the key output metrics that the simulation must generate and track (e.g., genetic gain, genetic variance components, allele frequencies, prediction accuracy values, simulated costs, inbreeding coefficients). This linkage ensures that the simulation is designed from the outset to provide the specific information needed to address the research questions effectively. The specificity of the objectives acts as a crucial filter, ensuring model parsimony by including only those biological processes, parameters, and complexities essential for achieving the stated goals, thereby balancing the need for realism with computational feasibility.

## **Section 2: Literature Review and Identification of Key Simulation Features**

A thorough review of existing literature is an indispensable prerequisite for designing a robust plant breeding simulation. This review should encompass several areas: published plant breeding simulation studies, fundamental quantitative genetics theory, and literature specific to the breeding practices and genetics of the target crop(s). The primary purposes of this review are to:

* Identify established and validated simulation methodologies and algorithms.  
* Understand the key biological processes and genetic principles relevant to the breeding objectives that must be incorporated into the model.  
* Compile realistic ranges and estimates for essential model parameters.  
* Learn about potential challenges encountered in previous simulation studies and effective solutions.  
* Identify knowledge gaps that the proposed simulation aims to address.

Based on the defined objectives and insights gleaned from the literature, the core biological processes to be represented must be identified. These typically include:

* **Meiosis and Recombination:** This is fundamental for simulating the creation of new genetic variation through sexual reproduction. The model must accurately simulate chromosome segregation and crossing over. Key considerations include the number of crossovers per meiosis, their distribution along the chromosome (potentially non-random), and the possibility of crossover interference. Algorithms often rely on genetic map distances (in centiMorgans) to determine recombination probabilities. Gene conversion, a non-reciprocal exchange, might also be included if deemed important. The simulation must also account for the specific reproductive biology of the target species, such as self-pollination versus cross-pollination, varying levels of ploidy (diploid, autopolyploid, allopolyploid), and potential complexities like differences in recombination rates between male and female meiosis (heterochiasmy).  
* **Mutation:** While often ignored in short-term breeding simulations, the introduction of new alleles via mutation is the ultimate source of genetic variation. If the simulation spans many generations or aims to model long-term evolutionary dynamics or the origin of novel traits, incorporating a realistic mutation rate may be necessary.  
* **Gene Action and Genetic Architecture:** The simulation must model how genes translate into traits. This involves defining the genetic architecture: the number of quantitative trait loci (QTLs) influencing the trait(s), their locations, and their effects. Models typically include additive effects, but may also incorporate dominance (interaction between alleles at the same locus) and epistasis (interaction between alleles at different loci) if these are known or hypothesized to be important for the trait(s) under study. The complexity of the assumed genetic architecture significantly impacts simulation outcomes and the effectiveness of different selection strategies.  
* **Selection:** This is the core process driving genetic improvement in breeding. The simulation must implement the specific selection strategy being investigated. This could range from simple phenotypic selection (choosing individuals based on their observed performance) to MAS (using markers linked to specific QTLs) or GS (using genome-wide markers to predict breeding values, GEBVs). Index selection, combining information on multiple traits or sources (phenotype, GEBV), is also common. Selection criteria (e.g., truncation threshold, index weights) and intensity must be specified.  
* **Mating Designs/Crossing Schemes:** The simulation needs to reflect how new populations are generated. This involves implementing specific mating designs, such as self-pollination, pair crosses between selected parents, full-sib mating, backcrossing to introgress specific alleles, diallel crosses to assess combining ability, or recurrent selection schemes involving intermating selected individuals.  
* **Population Structure:** The simulation must represent the relevant population structure, such as breeding populations of inbred lines, the development of hybrids, synthetic populations, or specific experimental populations like Recombinant Inbred Lines (RILs) or Doubled Haploids (DHs). Simulating the demographic history of the founder population can provide a more realistic starting point for genetic variation and linkage disequilibrium.  
* **Genotype-by-Environment Interaction (GxE):** As performance often varies across locations and years, modeling GxE is crucial for many breeding objectives, especially those related to stability or specific adaptation. This can be approached statistically (e.g., modeling environments as correlated traits, using environmental covariates) or mechanistically (using crop growth models).

The literature review also helps identify the key parameters that need to be defined, estimated, or varied in the simulation scenarios:

* **Genetic Parameters:** Number of chromosomes, genetic map lengths (cM), marker density and distribution, number of QTLs, distribution of QTL effects (e.g., gamma, normal), degree of dominance, epistatic interactions, initial allele frequencies in the founder population, genome-wide recombination rates, mutation rates (if applicable), trait heritability (h^2, H^2), genetic correlations among traits.  
* **Breeding Program Parameters:** Population sizes at various stages (e.g., number of crosses, progeny per cross, individuals in yield trials), selection intensity (proportion selected), number of breeding cycles or generations to simulate, details of the mating design, constraints on resources (e.g., maximum number of plots, genotyping budget).  
* **Environmental Parameters:** Number of simulated environments, variance components associated with environmental effects and GxE interactions, specific environmental data (e.g., weather variables) or derived environmental covariates if modeling GxE explicitly.

Finally, the literature review should ground the simulation in established **Theoretical Foundations**. Many simulations rely implicitly or explicitly on quantitative genetic theory, such as the breeder's equation (R \= h^2 S or variations) which predicts response to selection, concepts of variance partitioning (phenotypic, genotypic, environmental, GxE), heritability, genetic correlation, breeding values, linkage disequilibrium, and models of gene action. The infinitesimal model, assuming traits are controlled by infinitely many unlinked genes each with an infinitesimal effect, is a common theoretical simplification. It is crucial to understand the assumptions underlying these theories (e.g., additivity, normality, linkage equilibrium) and their limitations when designing and interpreting the simulation.  
A critical aspect emerging from the review process is the inherent trade-off in parameterization complexity versus realism. Simulations described in the literature range from relatively simple models based on established quantitative genetic equations to highly complex stochastic simulations aiming to capture intricate biological details like specific gene actions (epistasis, dominance), detailed recombination events, and complex GxE interactions. While incorporating more biological detail offers the potential for greater realism and predictive power, it comes at the cost of requiring a larger number of parameters. Accurately estimating these numerous parameters can be extremely challenging, often demanding extensive real-world data which may not be available, or forcing reliance on assumptions that could compromise the model's generality or validity. Conversely, simpler models with fewer parameters are easier to implement and calibrate but might fail to capture crucial biological interactions relevant to the specific breeding objectives, potentially leading to misleading conclusions. Therefore, the literature review must inform a careful decision regarding the appropriate level of model complexity and parameterization, consciously balancing the pursuit of biological realism against the practical constraints imposed by data availability and the inherent uncertainty in parameter estimation.

## **Section 3: Outlining Data Requirements**

The foundation of any credible and useful plant breeding simulation lies in the quality, quantity, and relevance of the input data used for its construction, parameterization, calibration, and validation. Inadequate or inaccurate data will inevitably lead to unreliable simulation outputs, regardless of the sophistication of the model itself. Therefore, a critical early step in the research plan is to meticulously outline the specific data requirements.  
The necessary data typically fall into three main categories:

1. **Genetic Data:** This encompasses information about the genetic makeup of the simulated individuals and populations.  
   * **Marker Data:** Genome-wide molecular marker information, such as Single Nucleotide Polymorphisms (SNPs), is essential for simulating modern breeding strategies like GS and MAS, and for accurately modeling recombination events. Data is often required for founder populations or representative germplasm sets. Common formats include Variant Call Format (VCF) or HapMap. For accurate simulation of meiosis and inheritance, phased haplotype data (knowing which alleles are on which homologous chromosome) is often necessary or highly desirable.  
   * **Genome Assembly / Genetic Map:** Information on the physical structure of the genome (chromosome lengths, gene order) and a genetic map providing marker positions in terms of recombination frequency (e.g., centiMorgans, cM) are required to simulate realistic recombination patterns.  
   * **QTL Information:** While not always essential (especially for GS simulations assuming infinitesimal effects), information on the location, effects (additive, dominance, epistatic), and allele frequencies of known major QTLs influencing the traits of interest can be highly valuable for parameterizing specific trait models or for validating the simulation's ability to capture known genetic effects.  
   * **Pedigree Information:** Records detailing the ancestry and relationships among individuals (parent-offspring links) are crucial for traditional breeding value estimation (e.g., using pedigree-based BLUP) and for understanding or simulating population structure and inbreeding.  
2. **Phenotypic Data:** This includes measurements of the traits of interest collected on relevant plant material.  
   * **Trait Measurements:** Historical or experimentally collected data on the target traits (e.g., yield, height, disease score, quality parameters) across a representative set of genotypes and environments are indispensable. This data is primarily used for estimating genetic parameters (e.g., heritability, genetic correlations, variance components), calibrating model parameters, and validating the simulation's predictive performance. Both raw plot-level data and potentially aggregated means (e.g., BLUEs or BLUPs) might be required.  
   * **Data Types:** Phenotypic data can be of various types: continuous quantitative traits (e.g., yield in kg/ha, plant height in cm), categorical traits (e.g., disease ratings on an ordinal scale like 1-5, or nominal categories like flower color), or binary traits (e.g., resistant/susceptible). The simulation's phenotype generation module must be able to handle the relevant data types.  
3. **Environmental Data ("Enviromics"):** This encompasses information about the environmental conditions under which phenotypic data was collected, crucial for understanding and modeling GxE interactions.  
   * **Site Information:** Metadata describing the experimental locations, including geographical coordinates (latitude, longitude), elevation, soil characteristics (type, texture, nutrient levels), and specific management practices applied (e.g., planting date, fertilization, irrigation).  
   * **Weather Data:** Time-series weather data, typically at daily resolution (though sometimes hourly), corresponding to the locations and growing seasons of the phenotypic trials. Key variables include minimum and maximum temperature, precipitation, solar radiation, humidity, and wind speed. This is essential for explicit GxE modeling or driving mechanistic crop growth models.  
   * **Environmental Covariates (ECs):** These are derived variables calculated from raw weather and site data, designed to capture specific environmental patterns or stresses relevant to plant growth (e.g., cumulative rainfall deficit during flowering, number of days above a critical heat stress threshold). ECs are often used as predictors in statistical GxE models.

Data for simulations can be sourced from various places:

* **Public Databases:** International repositories like INSDC (GenBank, ENA, DDBJ) for sequence data, Ensembl Plants for genome information, specific crop databases (e.g., MaizeGDB, Triticeae Toolbox, Phenopsis DB) for integrated genetic and phenotypic data, gene banks (e.g., GRIN-Global, EURISCO) for germplasm information, and climate data portals (e.g., NASA POWER, Daymet, WorldClim).  
* **Private/Collaborative Data:** Data generated within specific breeding programs, historical trial archives, ongoing experiments, or data shared through research consortia. Access to such data often requires collaboration agreements.  
* **Literature:** Published research articles can be a source for parameter estimates (e.g., heritability values, QTL effects, recombination rates reported for specific crops or populations), although these should be used with caution regarding their context-specificity.

Adherence to **Data Standards and Formatting** is critical for enabling data integration, sharing, and reproducibility. Key standards and practices include:

* **MIAPPE (Minimum Information About a Plant Phenotyping Experiment):** A community-driven standard providing a checklist and data model for describing the metadata associated with plant phenotyping experiments. It covers aspects like investigation details, study design, location, biological materials used (linking to standards like Multi-Crop Passport Descriptors, MCPD), environmental conditions, experimental factors, observed variables, and data files. Using MIAPPE ensures that phenotypic data is adequately contextualized for interpretation and reuse.  
* **Ontologies:** Employing controlled vocabularies or ontologies, such as the Crop Ontology (CO), Plant Ontology (PO), and Plant Trait Ontology (TO), for describing traits, experimental variables, and plant parts ensures consistency and semantic interoperability across datasets. Tools like Rightfield or OnotoMaton can assist in applying ontology terms within spreadsheets.  
* **Data Formats:** Utilizing standard, well-defined file formats facilitates data exchange and processing. Common formats include VCF for genomic variants, tabular formats (CSV, TSV) often structured according to MIAPPE or ISA-Tab frameworks for phenotypic and metadata, and potentially NetCDF for gridded climate data. The Breeding API (BrAPI) provides a standardized web service interface for programmatic access to breeding data.

Effective **Data Management and Integration** strategies are essential. This involves using database systems or data management platforms (e.g., FAIRDOM-SEEK, Dataverse, e\!DAL, COPO) capable of storing and linking the diverse data types. A central challenge is ensuring that genetic, phenotypic, pedigree, and environmental data can be unambiguously linked to the correct biological materials (e.g., specific plants, plots, or accessions) across different datasets and experiments. The field of "enviromics" specifically aims to develop methodologies for integrating these disparate environmental, genetic, and phenotypic data streams to better understand and predict crop performance.  
The following table provides a structured overview of the typical data requirements:  
**Table 3.1: Data Requirements for Plant Breeding Simulation**

| Data Category | Specific Data Example | Potential Sources | Common Formats | Relevant Standards/Ontologies | Integration Key(s) |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Genetic** | SNP Marker Genotypes | High-throughput genotyping, Public DBs (e.g., VCF) | VCF, HapMap, Plink | \- | Biological Material ID |
|  | Phased Haplotypes | Phasing software, Sequencing | VCF, Custom | \- | Biological Material ID |
|  | Genetic Map (cM positions) | Linkage mapping studies, Literature | CSV, Map file | \- | Chromosome, Marker ID |
|  | Genome Assembly (bp positions) | Genome sequencing projects, Public DBs | FASTA, GFF/GTF | \- | Chromosome, Marker ID |
|  | Known QTL Effects/Locations | QTL mapping studies, GWAS, Literature | Custom table, GFF | TO, CO | Chromosome, Position, Trait |
| **Phenotypic** | Grain Yield | Field trials, Historical records, Pheno DBs | CSV, TSV, Excel | MIAPPE, CO, TO | Biological Material ID, Plot ID, Env ID |
|  | Plant Height | Field trials, Greenhouse experiments | CSV, TSV, Excel | MIAPPE, CO, PO, TO | Biological Material ID, Plot ID, Env ID |
|  | Disease Score (Ordinal) | Disease nurseries, Field trials | CSV, TSV, Excel | MIAPPE, CO, TO | Biological Material ID, Plot ID, Env ID |
|  | Flowering Time (Days) | Field trials, Growth chambers | CSV, TSV, Excel | MIAPPE, CO, TO | Biological Material ID, Plot ID, Env ID |
| **Environmental** | Daily Max/Min Temperature | Weather stations, Climate DBs (e.g., Daymet) | CSV, NetCDF | MIAPPE (for trial context) | Location (Lat/Lon), Date, Env ID |
|  | Daily Precipitation | Weather stations, Climate DBs | CSV, NetCDF | MIAPPE (for trial context) | Location (Lat/Lon), Date, Env ID |
|  | Daily Solar Radiation | Weather stations, Climate DBs (e.g., NASA POWER) | CSV, NetCDF | MIAPPE (for trial context) | Location (Lat/Lon), Date, Env ID |
|  | Soil Type/Properties | Soil surveys, Site characterization | Text description, DB | MIAPPE | Location (Lat/Lon), Env ID |
|  | Management Practices | Trial records, Farmer surveys | Text description | MIAPPE | Env ID, Study ID |
| **Pedigree** | Parent-Offspring Records | Breeding program records, Herd books | CSV, Custom formats | \- | Individual ID, Parent IDs |

This table underscores the diverse nature of data needed and highlights the critical role of standardized identifiers (Biological Material ID, Environment ID) in linking information across these different categories.  
Ultimately, the availability and quality of these data types act as a primary constraint influencing the choice of simulation model and the achievable level of realism. The ambition to use sophisticated models, such as mechanistic crop growth models requiring detailed physiological parameters and daily weather data , or complex genetic models incorporating epistasis and detailed GxE , or genomic selection models needing large, well-characterized training populations , must be tempered by a realistic assessment of the available data. A lack of specific data types—be it high-resolution environmental data, accurately phased haplotypes for founders, or sufficiently large and relevant training sets for GS—may necessitate the use of simpler models or assumptions. This could potentially limit the simulation's ability to capture the nuances of complex biological phenomena like GxE or the long-term dynamics of selection, thereby impacting the reliability or scope of the simulation's predictions. Therefore, a thorough data audit and feasibility assessment must be conducted early in the planning phase.

## **Section 4: Selecting Appropriate Simulation Models and Algorithms**

Choosing the appropriate modeling paradigm and underlying algorithms is a critical decision in developing a plant breeding simulation. This choice is driven by the specific research objectives (Section 1), the availability of data (Section 3), the desired level of biological detail, and the available computational resources. Several distinct modeling approaches are commonly employed, each with its own strengths and limitations:

1. **Quantitative Genetic Models:** These models form the bedrock of many breeding simulations. They represent genetic effects and trait variation using statistical frameworks derived from quantitative genetics theory.  
   * *Description:* They typically partition phenotypic variance into genetic (additive, dominance, epistatic) and environmental components. A common simplification is the infinitesimal model, which assumes traits are influenced by a very large number of genes, each with a small effect. These models can be deterministic, using equations like the breeder's equation to predict population means and variances over time, or stochastic, simulating individual genotypes and phenotypes based on probability distributions.  
   * *Examples:* Foundational models implemented in software like QU-GENE , basic simulation capabilities in AlphaSimR , and tools like GREGOR.  
   * *Pros:* Relatively well-understood theoretical basis, computationally less demanding than highly mechanistic models (especially deterministic versions), sufficient for many comparative studies of selection strategies.  
   * *Cons:* May oversimplify complex biological realities such as specific gene interactions (epistasis) or the mechanisms underlying GxE. Deterministic models typically track population parameters, not individuals, limiting insights into variance changes or specific allele dynamics.  
2. **Mechanistic Crop Growth Models (CGMs):** These are process-based simulations focusing on the physiological mechanisms of plant growth and development.  
   * *Description:* CGMs simulate processes like photosynthesis, respiration, nutrient uptake, water transport, phenological development, and biomass allocation in response to environmental inputs (weather, soil, management). Increasingly, efforts focus on linking CGM parameters to genetic information (QTLs or specific genes), creating CGM-Gene-to-Phenotype (CGM-G2P) models that can simulate the performance of different genotypes across environments.  
   * *Examples:* Widely used models include APSIM, DSSAT, and AquaCrop , along with research-specific models developed to integrate genetic control.  
   * *Pros:* Offer a biologically explicit way to model GxE interactions based on underlying physiological responses to environmental factors. Potential for better extrapolation to novel environments or management scenarios. Provide a framework to link genetic variation to physiological processes.  
   * *Cons:* Highly complex, requiring extensive knowledge of crop physiology and significant effort for parameterization and calibration (often involving dozens of parameters per genotype). Computationally intensive. Integrating them fully within dynamic breeding program simulations remains challenging.  
3. **Agent-Based Models (ABMs) / Individual-Based Models (IBMs):** These models simulate systems by representing autonomous, interacting entities (agents).  
   * *Description:* In plant science, agents can represent individual plants competing in a population, organs within a plant (as in Functional-Structural Plant Models, FSPMs), or even cells. System-level behavior (e.g., population dynamics, spatial patterns) emerges from the local interactions and rules governing individual agents (a bottom-up approach).  
   * *Examples:* Forest gap models , FSPMs simulating detailed plant architecture , models of cellular interactions , or models simulating plant-plant competition for resources.  
   * *Pros:* Provide a natural way to incorporate individual heterogeneity, spatial context, and local interactions. Excellent for studying emergent phenomena. Highly flexible structure allows modeling complex behaviors and adaptations.  
   * *Cons:* Can become computationally very demanding, especially with large numbers of agents or complex rules. Parameterization and validation can be particularly challenging due to the focus on individual behaviors and emergent patterns. Scaling up to large spatial or temporal scales is often difficult. While powerful for ecological studies or detailed architectural modeling, they are less commonly used for simulating entire, multi-generational breeding programs compared to quantitative genetic models.  
4. **Genomic Selection (GS) Models:** These are primarily statistical models used *within* broader simulations to predict genetic merit.  
   * *Description:* GS models utilize genome-wide marker data to predict the Genomic Estimated Breeding Value (GEBV) of individuals, even those not yet phenotyped. Various statistical approaches exist, including linear models (GBLUP, RR-BLUP), Bayesian methods (BayesA, B, C, etc.), kernel methods (RKHS), and machine learning algorithms (SVM, Random Forest, Deep Learning).  
   * *Examples:* GBLUP is a common benchmark. Bayesian methods are noted for performance with fewer genes or early cycles. RKHS and various machine learning models are increasingly explored for capturing non-additive effects.  
   * *Pros:* Effective at capturing the collective effect of numerous small-effect QTLs typical of complex traits. Can significantly increase prediction accuracy and reduce breeding cycle time compared to phenotypic selection or MAS. Machine learning approaches offer potential to model complex, non-linear relationships (e.g., epistasis).  
   * *Cons:* Require large, well-phenotyped and genotyped training populations for accurate model building. Prediction accuracy depends heavily on factors like the genetic relationship between training and prediction sets, linkage disequilibrium (LD) extent, trait heritability, and genetic architecture. GxE interactions pose a significant challenge for standard GS models. Computational cost varies widely, from efficient methods like GBLUP to potentially intensive deep learning models.

Beyond the overall paradigm, specific **Key Algorithms** are needed to implement the core processes:

* **Genome Simulation:** To generate realistic starting genetic variation for founder populations, coalescent simulation algorithms (e.g., implemented in MaCS, used by AlphaSimR) are preferred. These simulate population history backwards in time to create haplotypes with realistic LD patterns based on specified demographic parameters (e.g., effective population size changes). For simulating subsequent generations forward in time, gene dropping algorithms are used, which track the transmission of chromosome segments from parents to offspring according to Mendelian rules and recombination events.  
* **Meiosis/Recombination Simulation:** Algorithms simulate the process of gamete formation. This involves randomly segregating homologous chromosomes and simulating crossover events between them based on probabilities derived from a genetic map (cM distances). Options may exist to model crossover interference (where one crossover influences the probability of another nearby) or assume no interference. Specific algorithms like random walks have been used. The algorithms must correctly handle the ploidy level of the species. There is also research interest in simulating the effects of manipulating recombination rates or patterns.  
* **Selection Algorithms:** These implement the process of choosing which individuals or families will become parents of the next generation. Common algorithms include simple truncation selection (selecting the top fraction based on phenotype or GEBV), index selection (using a weighted combination of multiple traits or information sources) , and potentially more complex optimization algorithms like optimal contribution selection that aim to balance genetic gain with control of inbreeding or maintenance of diversity.  
* **Phenotype Simulation:** Algorithms generate phenotypic values for simulated individuals. Typically, this involves summing the genetic effects (based on the individual's genotype at QTLs and the defined gene action model – additive, dominance, epistasis), adding environmental effects (often sampled from a distribution with a specified variance), incorporating GxE effects if modeled, and adding a random residual error term (often sampled from a normal distribution). The basic model is often represented as P \= \\mu \+ G \+ E \+ G \\times E \+ \\epsilon, where P is phenotype, \\mu is the overall mean, G is the genotypic value, E is the environmental effect, G \\times E is the interaction term, and \\epsilon is the residual error.

The following table summarizes the key characteristics of the main modeling paradigms:  
**Table 4.1: Comparison of Simulation Modeling Paradigms in Plant Breeding**

| Paradigm | Core Principle | Handling of Genetics | Handling of Environment/GxE | Typical Use Case in Breeding Sim. | Pros | Cons | Key Snippets |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| **Quantitative Genetic** | Statistical representation of genetic effects and variance components. | Additive, dominance, epistasis; Infinitesimal or finite loci models. | Often modeled as variance components or simple interaction terms; limited mechanistic insight. | Comparing selection strategies (phenotypic, MAS, GS), studying genetic architecture effects, predicting population-level gain. | Well-established theory, relatively simpler, computationally less demanding (esp. deterministic). | Can oversimplify complex biology (GxE mechanisms, specific gene actions); deterministic models lack individual tracking. |  |
| **Mechanistic CGM** | Process-based simulation of crop growth, development, and yield physiology. | Genetic control via parameters linked to physiological processes (CGM-G2P). | Explicitly models plant response to weather, soil, management; GxE emerges from process interactions. | Simulating GxE effects mechanistically, linking traits to physiology, virtual prototyping, climate change impact assessment. | Biologically realistic GxE modeling, potential for extrapolation, connects genetics to function. | Complex, requires extensive parameterization/calibration, computationally intensive, integration into breeding sim. frameworks evolving. |  |
| **Agent-Based (ABM)** | Simulation of autonomous agents interacting based on rules; bottom-up approach. | Can model individual genetic makeup and trait-based behaviors. | Environment can be agent(s) or spatial grid; interactions drive response. | Simulating competition within plots, spatial dynamics, FSPMs for architecture, specific ecological interactions. | Natural handling of heterogeneity, local interactions, emergence; flexible structure. | Computationally intensive, parameterization/validation challenges, scaling issues; less common for whole breeding program simulation. |  |
| **Genomic Selection (GS)** | Statistical prediction of breeding values (GEBVs) from genome-wide markers. | Uses marker effects (implicitly or explicitly) assuming LD with QTLs. | Often incorporates GxE statistically (e.g., multi-env models, reaction norms) or implicitly via environment-specific training. | Integrated *within* broader simulations to model selection based on GEBVs. | Captures polygenic effects, can increase accuracy/speed up cycles; ML methods can model non-linearity. | Requires large training data, accuracy context-dependent, GxE modeling is challenging, computational cost varies by method. |  |

An important trend is the development of **Hybrid Modeling Approaches** that combine elements from different paradigms to leverage their respective strengths. For instance, quantitative genetic simulators like QU-GENE have been linked with CGMs like APSIM to evaluate selection strategies under specific, mechanistically simulated environmental conditions. A common and powerful hybrid approach involves embedding sophisticated GS prediction models within a broader stochastic simulation framework that handles the population dynamics, crossing, and generation advancement aspects of a breeding program. Another promising avenue is using CGMs to simulate realistic GxE patterns or to predict intermediate physiological traits (endophenotypes) that can then be used as inputs or targets within GS models, potentially improving prediction accuracy for complex traits like yield, especially across diverse environments. ABMs could potentially simulate detailed within-plot competition, with the output feeding into a larger-scale quantitative model managing the overall breeding population. These hybrid strategies recognize that no single modeling paradigm is optimal for all aspects of a complex breeding system, and integrating approaches allows for more comprehensive and potentially more accurate simulations.

## **Section 5: Identifying Suitable Software Tools and Programming Languages**

The selection of appropriate software tools and programming languages is a critical step that significantly influences the feasibility, efficiency, flexibility, and long-term maintainability of the plant breeding simulation project. The choice depends on the required modeling capabilities, computational demands, the development team's expertise, and preferences regarding open-source versus commercial options.  
Several software packages have been developed specifically for simulating breeding programs:

* **AlphaSimR:** An R package that has gained significant traction due to its flexibility and comprehensive features.  
  * *Description:* It employs a scripting approach, allowing users to define complex, custom breeding programs rather than being confined to predefined schemes. It simulates diploid and autopolyploid species using a combination of coalescent simulation (via the integrated MaCS software) to generate realistic founder haplotypes and gene dropping for forward-in-time simulation of meiosis and breeding operations.  
  * *Features:* Supports various breeding actions (crossing, selfing, DH production), selection methods (phenotypic, GS using external R packages, index selection), advanced techniques like speed breeding and backcrossing, and offers basic methods for modeling GxE (correlated traits or a latent environmental variable). It is designed for simulating entire breeding programs over multiple generations.  
  * *Language & License:* R, Open source.  
* **QU-GENE (and related modules like QuLine):** A historically significant platform focused on quantitative genetic analysis.  
  * *Description:* Developed to explore the implications of relaxing assumptions in classical quantitative genetics, particularly focusing on GxE and epistasis through its flexible E(N:K) genetic model. QuLine specifically simulates line breeding programs. It demonstrated the potential for linking quantitative genetic simulations with crop models like APSIM.  
  * *Features:* Strong focus on modeling complex genetic architectures (epistasis) and GxE interactions. Allows comparison of selection strategies.  
  * *Language & License:* Likely a compiled, older platform. Availability and support status may be uncertain.  
* **PyBrOpS (Python Breeding Optimizer and Simulator):** A relatively new Python package offering simulation and optimization capabilities.  
  * *Description:* Built with a modular, script-based philosophy in Python, aiming for extensibility. It uses NumPy arrays for efficient genotype/genome representation and supports common data formats like VCF and HDF5.  
  * *Features:* Includes standard simulation components like genotype handling and genetic map functions (Haldane, Kosambi). Its unique feature is the integration of multi-objective optimization algorithms directly within the breeding simulation framework, allowing for simultaneous optimization of potentially conflicting breeding goals (e.g., gain vs. diversity).  
  * *Language & License:* Python, Open source.  
* **ChromaX:** A Python library specifically designed for high-performance, GPU-accelerated simulations.  
  * *Description:* Leverages the JAX library in Python to enable computations on CPUs, GPUs, and TPUs, aiming for significant speedups compared to traditional CPU-based simulators. Requires phased genotype data as input.  
  * *Features:* Focuses on accelerating core breeding simulation tasks: genetic recombination, doubled haploid induction, selection (based on various scoring functions like breeding value or phenotype), GEBV calculation, and basic GxE simulation. Claims substantial performance gains, particularly for large-scale crossing simulations on GPUs.  
  * *Language & License:* Python (using JAX), Open source (3-Clause BSD).  
* **MoBPS (Modular Breeding Program Simulator):** An R package designed for efficiency and flexibility, often used with its web interface, MoBPSweb.  
  * *Description:* Provides a framework for simulating diverse breeding programs using a modular structure based on cohorts (nodes) and breeding actions (edges). MoBPSweb offers a user-friendly graphical interface for designing, running, and comparing simulation scenarios.  
  * *Features:* Efficient simulation engine in R, supports various genetic models and breeding actions, includes modules for analyzing outputs like phenotypes, breeding values, accuracy, and inbreeding.  
  * *Language & License:* R, Open source.  
* **Other Tools:** Several other tools have been mentioned in the literature, often with more specific focuses or older implementations: Plabsoft (data analysis and simulation) , MBP , GREGOR (predicts mean outcomes, MS-DOS based) , PLABSIM (marker-assisted backcrossing) , GENEFLOW (genetic diversity studies) , COGENFITO. Simple simulations can even be implemented in spreadsheet software like Excel for educational purposes.

The choice of **Programming Language** is often tied to the chosen software package but also reflects broader trends and team expertise:

* **R:** A dominant language in statistical genetics and bioinformatics. Benefits from a vast ecosystem of packages for statistical analysis, genetic data manipulation, and visualization. AlphaSimR and MoBPS are native R packages, allowing seamless integration with other R tools. While powerful for statistical tasks, base R can sometimes be slower for computationally intensive loops compared to compiled languages or optimized Python libraries.  
* **Python:** Rapidly gaining prominence in scientific computing, data science, and machine learning. Strong libraries like NumPy, SciPy, and Pandas provide efficient numerical computation and data handling. The emergence of libraries like JAX enables high-performance computing on GPUs/TPUs, leveraged by ChromaX. PyBrOpS is also Python-based. Python's extensive machine learning ecosystem is an advantage if integrating complex prediction models is a goal.  
* **Other Languages:** Older simulation tools might be written in compiled languages like Fortran or C++ for performance. Standalone executables may not require programming knowledge but offer less flexibility.

When selecting a tool, several **Criteria** should be considered:

* **Flexibility & Extensibility:** Can the tool model the specific, potentially complex, breeding program structure required? Scripting approaches (AlphaSimR, PyBrOpS) generally offer more flexibility than tools with fixed menus or structures. Modularity allows easier modification and addition of new components.  
* **Functionality:** Does the software support the necessary biological models (e.g., ploidy levels, gene action like epistasis), algorithms (e.g., specific recombination models, selection types like GS or index selection), and advanced features (e.g., speed breeding, GxE modeling, optimization) dictated by the research objectives?.  
* **Computational Efficiency & Scalability:** How quickly does the simulation run, especially for large-scale scenarios (many individuals, markers, generations, replicates)? Does it scale well? Is parallel processing or GPU acceleration supported or needed?.  
* **Usability & Learning Curve:** How easy is the software to install, configure, and use? Is the scripting language or interface intuitive? Is the documentation comprehensive and clear? Is there an active user community for support?. Web interfaces like MoBPSweb can significantly enhance usability.  
* **Cost & Licensing:** Is the software open source and freely available, or does it require a commercial license? Open-source tools generally foster wider adoption and community development.  
* **Integration:** Can the tool easily import required data formats (e.g., VCF, genetic maps)? Can it interface with other software, such as external statistical packages for GS model training (e.g., AlphaSimR calling SVM from another R package ) or potentially crop growth models?.

The following table compares some of the key modern software packages:  
**Table 5.1: Comparison of Key Plant Breeding Simulation Software**

| Software | Language | Core Approach | Key Features | Flexibility | Scalability/Efficiency | Usability/Docs | License | Key Snippets |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| AlphaSimR | R | Scripting | Diploid/Autopolyploid, GS, GxE (basic), Epistasis, Speed Breeding, Index Sel. | High | Moderate (CPU) | Good/Improving | Open Source |  |
| PyBrOpS | Python | Scripting, Modular | Multi-objective optimization, VCF/HDF5 I/O, Extensible | High | Moderate (CPU) | Developing | Open Source |  |
| ChromaX | Python | Library (JAX) | GPU/CPU/TPU acceleration, Focus on speed for core tasks (recomb., sel.) | Moderate | Very High (GPU) | Developing | Open Source |  |
| QU-GENE\* | N/A | Platform | E(N:K) model, Focus on GxE & Epistasis, Linked to CGMs | Moderate | Older platform | Limited/Uncertain | N/A |  |
| MoBPS | R | Modular (Nodes/Edges) | Efficient R engine, Web interface (MoBPSweb), Analysis modules | High | High (CPU) | Good (esp. w/ Web) | Open Source |  |
| *Note: QU-GENE is included for historical context; its current availability and support may be limited.* |  |  |  |  |  |  |  |  |

A notable trend is the **Emerging Python Ecosystem** for breeding simulation. While R has a strong historical presence with established tools like AlphaSimR and MoBPS , the recent development of Python packages like PyBrOpS (offering integrated optimization) and ChromaX (focusing on GPU speed) signifies a growing investment in Python for this domain. This likely reflects Python's strengths in broader scientific computing, particularly in machine learning , and the increasing need to handle larger datasets and computationally intensive tasks efficiently. Researchers planning simulation projects should now actively consider both R and Python environments, evaluating the specific features and performance characteristics offered by tools in each ecosystem relative to their project's needs.

## **Section 6: Developing the Model Design Plan**

Once objectives are set, literature reviewed, data needs assessed, and potential tools identified, the next crucial phase is developing a detailed plan for the simulation model's design. This involves translating the conceptual understanding into a concrete, implementable structure. A systematic approach is essential to manage complexity and ensure all necessary components are included and interact correctly. The structured, multi-step process used by simulators like AlphaSimR provides a useful framework for organizing this design phase.  
The key steps in developing the model design plan are:

1. **Outline the Breeding Program:** This initial step involves creating a high-level blueprint of the breeding program to be simulated. It requires defining the target species characteristics (e.g., ploidy level, mode of reproduction \- selfing, crossing, clonal), the specific traits targeted for improvement, the sequence of breeding stages (e.g., initial crosses, generation advance, nursery evaluations, preliminary yield trials (PYTs), advanced yield trials (AYTs), elite yield trials (EYTs)), the typical duration of each stage and the overall cycle length, the selection methods employed at each stage, and any known logistical or resource constraints (e.g., maximum population sizes, budget limitations).  
2. **Specify Global Parameters:** Define the parameters that govern the overall simulation environment and genetic system. This includes details of the genetic map (number of chromosomes, length in cM), marker density, assumed mutation and recombination rates, the number and distribution of QTLs affecting each trait, the magnitude and nature of QTL effects (additive, dominance, epistasis), initial allele frequencies in the founders, trait heritabilities (narrow-sense and/or broad-sense), genetic correlations between traits, the magnitude of environmental variance, and parameters defining GxE interactions if modeled explicitly. These parameters should be derived from the literature review (Section 2\) and available data (Section 3).  
3. **Simulate Genomes and Founders:** Create the initial pool of genetic variation that the simulated breeding program will operate on. The preferred method is often coalescent simulation (e.g., using MaCS) which generates founder haplotypes with realistic patterns of LD based on assumptions about the species' demographic history. Alternatively, real genotype data from a diverse panel can be imported, or simplified random haplotypes can be generated. Once founder genomes are created, the defined trait architecture is imposed by assigning effects (additive, dominance, epistatic) to the simulated QTLs according to specified distributions (e.g., normal, gamma) and defining the genetic values for each founder individual.  
4. **Define Input Variables:** Explicitly list all external data and parameters the simulation model requires to run. This includes the founder population's genotypic data, the genetic map, parameter files defining trait architecture and genetic effects, environmental data series (if GxE or CGMs are used), and parameters specifying the breeding strategy itself (e.g., population sizes at each stage, selection intensity, number of cycles).  
5. **Structure the Simulation Workflow (Breeding Pipeline):** Define the step-by-step flow of the simulation, mimicking the progression of individuals and populations through the breeding program over time.  
   * *Breeding Stages:* Clearly define each distinct stage (e.g., crossing block, F1 generation, F2 selection nursery, DH production, PYT, AYT) and the transitions between them.  
   * *Time Steps/Cycles:* Establish the simulation's time increment (e.g., year, generation, season). Critically, design the workflow to handle the overlapping nature of breeding cycles, where multiple generations coexist in the pipeline simultaneously.  
   * *Population Management:* Specify rules for population sizes at entry and exit of each stage, how individuals/families are advanced, selected, or discarded, and how resources are allocated across stages.  
6. **Implement Core Processes:** Define the algorithms and logic for the key biological and breeding activities within the workflow.  
   * *Parent Selection:* Specify the criteria used to select parents for the next cycle of crossing. This could be based on simulated phenotypic performance, estimated breeding values (EBVs from pedigree or GEBVs from genomic data), selection indices combining multiple traits, or optimization methods considering genetic diversity.  
   * *Crossing/Mating Design:* Implement the chosen strategy for pairing selected parents (e.g., selfing, specific pair crosses, diallel, polycross, random mating within selected groups). Simulate meiosis (including recombination based on the genetic map) in the selected parents to generate the genotypes of the progeny according to Mendelian inheritance.  
   * *Phenotyping:* Simulate the generation of phenotypic data for individuals evaluated at specific stages. This involves applying the defined phenotype model (P \= G \+ E \+ G \\times E \+ \\epsilon), incorporating genetic values derived from QTL effects, environmental effects (potentially varying across simulated locations/years), GxE interaction effects, and random residual error. If simulating field trials, the model might also need to account for experimental design factors like plot effects, replication, or blocking.  
   * *Selection:* Apply the defined selection criteria (based on simulated phenotypes, GEBVs, or index values) to choose which individuals or lines advance to the next stage or are selected as parents.  
7. **Define Output Metrics:** Specify precisely what data needs to be recorded from the simulation at each relevant time step or breeding cycle. These metrics must directly address the research objectives (Section 1\) and align with the evaluation criteria (Section 9). Examples include population mean genetic value for target traits, genetic variance components, allele frequencies at specific loci or across the genome, patterns of LD, average pedigree or genomic inbreeding coefficients, accuracy of GEBV predictions (if GS is simulated), simulated costs, lists of selected individuals/lines, and trait distributions.  
8. **Incorporate Burn-in Phase:** Consider including an initial phase in the simulation that models a period of historical breeding, typically using simpler selection methods (e.g., phenotypic selection) before the main "future phase" where new strategies are tested. The purpose of the burn-in phase is crucial: real breeding populations are not randomly generated but possess genetic architectures (allele frequencies, LD patterns, levels of genetic variance) shaped by past selection and mating. Simulating this history creates a more realistic genetic context (e.g., established LD, reduced variance compared to initial founders) from which to evaluate the *incremental* impact of introducing novel breeding strategies in the future phase. Skipping the burn-in can lead to unrealistic starting conditions and potentially overestimate the benefits of new methods compared to their likely performance in an ongoing, established program.  
9. **Plan for Scenarios and Replication:** Design the "future phase" where the core comparisons are made. This involves setting up different scenarios that vary key parameters or implement alternative breeding strategies. Crucially, due to the inherent stochasticity in biological processes like meiosis (recombination) and often in selection or environmental effects, each scenario must be run for multiple independent replicates. Replication allows for the estimation of the mean outcome and the variability around that mean for each scenario, enabling robust statistical comparisons between strategies and accounting for chance events.

Throughout the design process, adopting a **Modular Design Principle** is highly recommended. Structuring the simulation code into relatively independent modules (e.g., a module for simulating meiosis, another for phenotypic selection, another for GS prediction) makes the model easier to develop, test, debug, modify, and potentially reuse components in future projects.  
It is also vital to recognize the **Interdependence of Design Choices**. The decisions made in one part of the design process invariably affect others. For example, the assumed genetic architecture (number of QTLs, presence of epistasis) directly influences which selection methods are likely to be most effective (e.g., GS generally outperforms MAS for highly polygenic traits ). The chosen population sizes impact achievable selection intensity and the efficiency of breaking undesirable linkages. The mating design affects the rate of inbreeding and the generation of useful genetic variance. The decision to explicitly model GxE necessitates specific environmental data inputs and influences how selection should be performed across different target environments. Therefore, the model design cannot be a purely linear process; it often requires iteration and a holistic view, considering the interplay and potential trade-offs between different components – genetic model, population structure, selection strategy, mating system, and environmental context – to arrive at a coherent and effective overall simulation design.

## **Section 7: Describing Model Validation and Calibration Methods**

Developing a simulation model is only part of the process; ensuring its credibility and relevance requires rigorous validation and calibration. These steps are essential for building confidence that the simulation accurately represents the real-world plant breeding system it aims to mimic and that its outputs are reliable for decision-making. It is crucial to distinguish between these two related but distinct processes :

* **Calibration:** The process of adjusting or tuning model parameters (often those that cannot be directly measured or are uncertain) so that the model's output aligns with observed data or known characteristics of the system.  
* **Validation:** The process of assessing how well the calibrated model reproduces reality, specifically by comparing its predictions against independent data sets that were *not* used during calibration.

**Calibration Methods:**  
The goal of calibration is to find parameter values that allow the model to best reproduce observed patterns or data points.

* **Parameters for Calibration:** Calibration typically focuses on parameters that are difficult to measure directly or have high uncertainty. In breeding simulations, this might include QTL effect sizes, variance components (genetic, GxE, error), recombination rates, or parameters within mechanistic crop models governing physiological processes. Parameters with well-established values from direct measurement or reliable literature might be fixed.  
* **Calibration Data:** A dedicated 'training' or 'calibration' dataset is required. This should ideally be independent of the data used later for validation. Sources can include historical data from the breeding program being modeled, results from specific experiments designed for parameter estimation, or published parameter values.  
* **Calibration Techniques:**  
  * *Manual Tuning ('Trial-and-Error'):* Involves iteratively adjusting parameters based on expert judgment and observing the impact on model outputs until a satisfactory match with the calibration data is achieved. While common, especially historically, this method is subjective, potentially time-consuming, and may not find the optimal parameter set.  
  * *Automated Calibration:* Employs computational search algorithms to systematically find parameter values that minimize a predefined objective function (e.g., the sum of squared errors between simulated and observed values). Various algorithms can be used, including optimization routines (gradient-based, derivative-free), Bayesian inference methods (e.g., MCMC), or evolutionary algorithms. Software tools like PEST, frameworks like SUFI2 (used with SWAT), or general optimization libraries in R or Python can facilitate this.  
* **Parameter Identifiability:** A potential challenge, especially in complex models with many parameters, is non-identifiability – where different combinations of parameter values can produce very similar model outputs. This makes it difficult to uniquely determine the 'true' parameter values from the calibration data alone. Sensitivity analysis can help identify parameters that are difficult to estimate.

**Validation Methods:**  
Validation assesses the model's predictive capability and its ability to represent the real system beyond the specific data used for calibration.

* **Validation Data:** The cornerstone of validation is the use of independent data. This means using datasets that were not involved in the calibration process. Ideally, these data should come from different experimental sites, years, populations, or management conditions than the calibration data. If data is scarce, statistical techniques like k-fold cross-validation (where the data is repeatedly split into different calibration and validation subsets) can be employed, though truly independent data is preferred.  
* **Comparison Points:** The validation involves comparing specific outputs from the calibrated simulation model against corresponding real-world observations or well-established theoretical benchmarks.  
  * *Historical Data Comparison:* Simulate the breeding program over a historical period and compare simulated trends (e.g., genetic gain per year, changes in trait means or variances) with actual recorded data from the program, if available.  
  * *Predictive Accuracy Assessment:* If the simulation incorporates predictive models like GS, a key validation step is to compare the accuracy (e.g., correlation between predicted GEBVs and observed phenotypes or true breeding values if known) achieved within the simulation against the prediction accuracy obtained from cross-validation using real phenotypic and genotypic data from the target population.  
  * *Pattern-Oriented Modeling (POM):* Particularly relevant for complex models (like ABMs or CGMs), POM involves assessing whether the model can simultaneously reproduce multiple patterns observed in the real system at different scales or levels of organization, rather than just fitting specific data points. This provides a more robust test of the model's structural realism.  
* **Goodness-of-Fit Metrics:** Quantitative metrics are used to measure the discrepancy between simulated outputs and validation data. Common metrics include Pearson correlation coefficient, coefficient of determination (R^2), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and measures of bias. The choice of metric depends on the nature of the output being compared.

**Sensitivity Analysis (SA):**  
SA is a crucial tool used alongside calibration and validation to understand model behavior and uncertainty.

* **Purpose:** SA investigates how changes in model input parameters affect the model's outputs. Its key uses include: identifying the most influential parameters (guiding calibration efforts and model simplification), understanding the mechanisms driving model behavior, assessing the robustness of simulation results to parameter uncertainty, and exploring interactions between parameters.  
* **Methods:**  
  * *Local SA (One-at-a-time, OAT):* Varies one parameter at a time while keeping others fixed at nominal values. Simple to implement but fails to capture interactions between parameters.  
  * *Global SA (GSA):* Simultaneously varies multiple parameters across their defined ranges of uncertainty. GSA methods provide a more comprehensive understanding of parameter influence and interactions. Common GSA techniques include:  
    * Screening methods (e.g., Morris method): Efficiently identify influential parameters from a large set.  
    * Variance-based methods (e.g., Sobol' indices, Fourier Amplitude Sensitivity Test \- FAST, Extended FAST \- EFAST): Quantify the contribution of each parameter (and their interactions) to the variance of the model output.  
    * Regression-based methods: Use regression analysis between inputs and outputs to estimate sensitivity.  
* **Application:** SA can be performed *before* calibration to identify the most critical parameters needing careful estimation, thereby simplifying the calibration task. It can also be performed *after* calibration to assess how uncertainty in the calibrated parameter values propagates to uncertainty in the model predictions. Conducting SA across different time points in dynamic simulations can reveal how parameter importance changes during the simulated process.

**Best Practices for Validation and Calibration:**

* **Data Separation:** Maintain strict independence between calibration and validation datasets to avoid overly optimistic assessments of model performance.  
* **Parameter Plausibility:** Ensure that calibrated parameter values remain within realistic biological or physical ranges. Avoid "over-fitting" where parameters take on unrealistic values simply to match the calibration data. Parameters should ideally represent measurable quantities or processes.  
* **Parameter Set Documentation:** Clearly document the final parameter values used after calibration. This validated parameter set must be used consistently for subsequent simulation experiments and scenario analyses, without further tuning unless explicitly part of a re-validation process.  
* **Iterative Refinement:** Recognize that model development, calibration, and validation often form an iterative cycle. Discrepancies identified during validation may necessitate revisiting the model structure, assumptions, or parameterization, followed by recalibration and re-validation.  
* **Transparency and Reporting:** Thoroughly document the entire calibration and validation process, including the datasets used, the specific methods applied (calibration algorithms, validation comparisons, SA techniques), the metrics calculated, and the results obtained. This transparency is crucial for reproducibility and scientific credibility.

The application of **Sensitivity Analysis offers a powerful strategy for enhancing calibration efficiency and enabling model simplification**. Complex simulations, particularly those involving mechanistic crop models or detailed genetic architectures, can involve a large number of parameters. Attempting to calibrate all parameters simultaneously can be computationally prohibitive and may lead to identifiability problems, where the available data cannot uniquely resolve all parameter values. By employing GSA methods (like EFAST or Sobol') early in the process, researchers can quantitatively rank parameters based on their influence on the key simulation outputs relevant to the study's objectives. This allows calibration efforts to be strategically focused on the most sensitive parameters – those that drive the model's behavior most strongly. Less sensitive parameters might then be reasonably fixed based on literature values or expert estimates, significantly reducing the dimensionality of the calibration problem. This targeted approach not only saves considerable computational time and effort but can also lead to a more robust and reliable calibration by concentrating on the parameters that truly matter.  
However, a significant challenge lies in **validating the long-term dynamics or the prediction of rare events** simulated by the model. While comparing simulation outputs to short-term experimental results (e.g., yields from multi-environment trials over a few years ) or observed historical trends is often feasible , obtaining comprehensive real-world data that spans decades of breeding activity and tracks all relevant variables (like allele frequencies at specific loci or detailed environmental sequences) is typically impossible. Similarly, empirically validating the model's ability to predict the occurrence and impact of rare beneficial mutations or the system's response to infrequent, extreme environmental conditions (e.g., unprecedented drought or heat waves) is inherently difficult due to the scarcity of observational data for such events. This implies a limitation to purely empirical validation for certain simulation objectives. Confidence in long-term predictions or simulations of novel scenarios must therefore rely more heavily on the theoretical soundness and structural realism of the model (i.e., ensuring the underlying mechanisms are represented correctly), complemented by extensive sensitivity analyses that explore the impact of uncertainties in parameters and future environmental conditions.

## **Section 8: Anticipating Potential Challenges and Proposing Solutions**

Developing sophisticated plant breeding simulations is a complex undertaking, fraught with potential challenges. Proactively anticipating these difficulties and planning mitigation strategies is crucial for successful project execution.  
**Challenge 1: Computational Cost and Scalability**

* *Description:* Simulating realistic breeding programs often involves large populations (thousands or tens of thousands of individuals), dense genome-wide marker data (millions of SNPs), complex genetic models (including epistasis), multiple environments, numerous stochastic replicates for robust conclusions, and simulations spanning many generations or breeding cycles. The combinatorial complexity can lead to excessive computational demands, making simulations slow or infeasible on standard hardware. Optimizing breeding program designs across a large parameter space further exacerbates this challenge.  
* *Solutions/Mitigation:*  
  * **Hardware & Software Optimization:** Utilize high-performance computing (HPC) clusters for parallel execution of replicates or computationally intensive tasks. Employ software specifically designed for efficiency, potentially leveraging GPU acceleration (e.g., ChromaX) for tasks like recombination or matrix operations.  
  * **Model Parsimony:** Based on sensitivity analysis (Section 7), simplify model components that have minimal impact on the outputs relevant to the objectives. Avoid unnecessary complexity.  
  * **Efficient Algorithms:** Implement computationally efficient algorithms, particularly for repetitive tasks like GEBV prediction (e.g., GBLUP is often faster than complex ML models for standard additive scenarios ) or relationship matrix calculations.  
  * **Smart Parameter Search:** When optimizing breeding designs or parameters, use intelligent search algorithms (e.g., Bayesian optimization, evolutionary algorithms) instead of exhaustive grid searches to explore the parameter space more efficiently.  
  * **Data Reduction:** Explore the use of reduced marker density panels combined with imputation techniques, provided validation shows acceptable accuracy loss for the specific application.

**Challenge 2: Data Integration and Availability**

* *Description:* As detailed in Section 3, simulations require diverse data types (genetic, phenotypic, environmental, pedigree). Acquiring, cleaning, formatting, and integrating these data from disparate sources (public databases, private records, field sensors) presents a significant logistical and technical hurdle. Missing data, inconsistent formats, and lack of standardization are common problems. Insufficient data directly limits the complexity of models that can be realistically parameterized and validated \[Insight 3.1\].  
* *Solutions/Mitigation:*  
  * **Embrace Standards:** Proactively adopt data standards (e.g., MIAPPE for phenotyping metadata) and ontologies (e.g., Crop Ontology) from the outset.  
  * **Utilize Data Management Platforms:** Employ specialized databases or platforms designed for breeding data that facilitate linking different data types (e.g., linking phenotype data back to specific genotyped material and the environment it was tested in).  
  * **Develop Data Pipelines:** Create automated workflows for data cleaning, formatting, and integration.  
  * **Imputation Strategies:** Use appropriate statistical methods to handle missing phenotypic or genotypic data, documenting the methods used and assessing their potential impact.  
  * **Foster Collaboration:** Engage in collaborations and data-sharing agreements to access necessary datasets, particularly private breeding program data.  
  * **Simulate Data Limitations:** If critical data is unavailable, use the simulation itself to perform sensitivity analyses on the potential impact of missing data or assumptions made in its place.

**Challenge 3: Modeling Complex Genetic Effects (Epistasis, Dominance)**

* *Description:* While additive genetic effects are often the primary drivers of selection response, non-additive effects like dominance and epistasis can influence trait expression and short-term selection dynamics. Accurately modeling these interactions requires more complex genetic models, increases the number of parameters to estimate, adds computational burden, and may require specific experimental designs for estimation. Their importance can vary significantly depending on the trait, species, and population history.  
* *Solutions/Mitigation:*  
  * **Appropriate Model Selection:** If modeling non-additivity is crucial for the objectives, choose simulation software and genetic models capable of incorporating these effects (e.g., specific quantitative genetic formulations, machine learning approaches like RKHS or deep learning that can implicitly capture interactions).  
  * **Informed Parameterization:** Use available empirical evidence (e.g., from specific genetic studies on the target traits/species) or literature reviews to guide the parameterization of non-additive effects (e.g., magnitude, frequency of interacting loci).  
  * **Sensitivity Analysis:** Evaluate how sensitive the simulation outcomes are to the assumptions made about the presence and magnitude of dominance and epistasis.  
  * **Focus on Additivity:** For simulations focused on long-term gain or where data on non-additive effects is scarce, simplifying the model to primarily include additive effects might be a justifiable and pragmatic approach, acknowledging the potential limitations.

**Challenge 4: Modeling Genotype-by-Environment Interaction (GxE)**

* *Description:* GxE is a pervasive phenomenon in plant breeding, meaning that the relative performance of genotypes changes across different environments (locations, years, management conditions). This complicates selection decisions aimed at developing broadly adapted or specifically adapted cultivars. Simulating realistic GxE patterns that capture the complexity of environmental influences and genetic sensitivities remains a significant challenge.  
* *Solutions/Mitigation:*  
  * **Statistical GxE Models:** Implement statistical approaches within the simulation, such as:  
    * *Multi-Trait Models:* Treat performance in each environment as a separate but genetically correlated trait. Requires estimation or assumption of the genetic correlation matrix between environments.  
    * *Factor Analytic (FA) or Reaction Norm Models:* Use environmental covariates (ECs) or latent environmental factors to model how genotypic effects change along environmental gradients. Requires identifying and obtaining relevant EC data.  
  * **Mechanistic Crop Growth Models (CGM-G2P):** Use CGMs where GxE arises mechanistically from the simulated interaction between genotype-specific physiological parameters and dynamic environmental inputs. This is biologically appealing but data-intensive for parameterization and computationally demanding.  
  * **Simplified Models:** Employ simpler GxE structures if sufficient for the objectives, such as assuming random GxE effects drawn from a distribution or using simplified latent variable approaches.

**Challenge 5: Parameter Uncertainty and Estimation**

* *Description:* Many parameters required by the simulation model (e.g., heritabilities, QTL effects, recombination frequencies, error variances) are not known precisely but are estimated from data, carrying inherent uncertainty. Other parameters might be poorly characterized or based on assumptions. Running simulations using only single point estimates for these parameters ignores this uncertainty and can lead to overconfidence in the results.  
* *Solutions/Mitigation:*  
  * **Rigorous Parameter Estimation:** Use robust statistical methods and diverse, relevant datasets to estimate parameters whenever possible.  
  * **Sensitivity Analysis:** Explicitly quantify how uncertainty in key input parameters translates into uncertainty in the simulation outputs (as discussed in Section 7).  
  * **Scenario Analysis:** Run the simulation under different plausible sets of parameter values (e.g., low, medium, high heritability) to assess the robustness of the conclusions across a range of uncertainties.  
  * **Bayesian Frameworks:** Consider using Bayesian statistical approaches for parameter estimation or within the simulation itself, as they naturally incorporate prior knowledge and provide posterior distributions that represent parameter uncertainty.

**Challenge 6: Balancing Genetic Gain and Genetic Diversity**

* *Description:* Breeding programs inherently aim to increase the frequency of favorable alleles, which often involves intense selection pressure. A potential consequence is the rapid loss of overall genetic diversity, including potentially useful rare alleles, and an increase in inbreeding. This can limit long-term genetic progress, reduce adaptability to future environmental changes or breeding goals, and increase the risk of inbreeding depression. Simulations comparing strategies must often consider this trade-off.  
* *Solutions/Mitigation:*  
  * **Track Diversity Metrics:** Implement measures within the simulation to monitor genetic diversity over time. This can include tracking overall genetic variance, effective population size (N\_e), allele frequencies (especially for rare alleles), or pedigree/genomic inbreeding coefficients.  
  * **Simulate Constrained Selection:** Implement and evaluate selection strategies specifically designed to manage diversity while maximizing gain, such as Optimal Contribution Selection (OCS) or other methods that penalize high co-ancestry among selected parents.  
  * **Evaluate Mating Designs:** Compare different mating designs (e.g., avoiding crosses between close relatives, structured crossing schemes) for their impact on maintaining diversity.  
  * **Model Germplasm Introduction:** Simulate strategies for periodically introducing novel genetic variation from diverse sources (e.g., landraces, wild relatives) into the elite breeding pool, evaluating the benefits versus potential linkage drag.

The following table summarizes these common challenges and potential mitigation strategies:  
**Table 8.1: Common Simulation Challenges and Mitigation Strategies**

| Challenge | Description | Potential Mitigation Strategies | Relevant Snippets |
| :---- | :---- | :---- | :---- |
| **Computational Cost/Scalability** | Simulations are too slow or require excessive resources due to large scale or complexity. | Use HPC, GPU acceleration (e.g., ChromaX), efficient algorithms (e.g., GBLUP), model simplification (guided by SA), smart parameter search (e.g., Bayesian optimization), reduced marker density/imputation. |  |
| **Data Integration/Availability** | Difficulty obtaining, cleaning, standardizing, and integrating diverse genetic, phenotypic, environmental data. | Adhere to data standards (MIAPPE), use breeding databases, develop data pipelines, use statistical imputation, foster collaboration, simulate impact of missing data. |  |
| **Modeling Complex Genetic Effects** | Difficulty in accurately modeling and parameterizing non-additive effects (dominance, epistasis). | Use appropriate models (specific quantitative genetic, ML), inform parameterization with empirical data, perform sensitivity analysis, focus on additive effects if justified by objectives/data limitations. |  |
| **Modeling GxE Interaction** | Accurately simulating how genotype performance varies across environments is challenging. | Use multi-trait models, environmental covariates (ECs), reaction norms, mechanistic CGMs (CGM-G2P), or simplified GxE structures depending on objectives and data. |  |
| **Parameter Uncertainty** | Many model parameters are estimates with uncertainty, which is often ignored. | Use robust estimation methods, perform sensitivity analysis to assess impact of uncertainty, conduct scenario analysis across parameter ranges, consider Bayesian approaches. |  |
| **Balancing Gain vs. Diversity** | Intense selection for short-term gain can erode genetic diversity needed for long-term progress. | Track diversity metrics (variance, Ne, inbreeding) in simulation, implement constrained selection (e.g., OCS), evaluate diversity-preserving mating designs, simulate germplasm introgression strategies. |  |

It is important to recognize the **interconnectedness of these challenges**. Efforts to address one challenge often impact others. For instance, choosing a more complex model to better capture GxE (Challenge 4\) or epistasis (Challenge 3\) will likely increase computational cost (Challenge 1\) and demand more comprehensive data for parameterization and validation (Challenges 2 & 5). Similarly, implementing sophisticated selection algorithms to manage the gain-diversity trade-off (Challenge 6), such as optimal contribution selection , may also increase computational requirements (Challenge 1). Conversely, successfully addressing data integration issues (Challenge 2\) might enable the use of more realistic models, but could simultaneously exacerbate computational bottlenecks (Challenge 1). Therefore, proposed solutions and mitigation strategies should be considered holistically, acknowledging potential trade-offs and seeking a balanced approach that best meets the research objectives within the practical constraints of the project.

## **Section 9: Establishing Evaluation Criteria and Metrics**

To objectively assess the performance and utility of the developed plant breeding simulation, it is essential to establish clear evaluation criteria and quantifiable metrics *a priori*. These metrics should be directly linked to the research objectives defined in Section 1 and provide a basis for comparing different simulated breeding strategies or model configurations. A multi-faceted evaluation approach is typically necessary, considering various aspects of the simulation's output and behavior.  
Key categories for evaluation criteria include:

1. **Predictive Accuracy/Performance:** This criterion is particularly relevant when the simulation involves predictive modeling, such as genomic selection (GS). It assesses how well the models within the simulation predict the genetic merit or phenotypic performance of individuals.  
   * *Metrics:* Common metrics include the Pearson correlation coefficient between predicted values (e.g., GEBVs) and true genetic values (if known in the simulation) or observed phenotypic values (in validation against real data), Root Mean Squared Error (RMSE) of prediction, prediction bias, and the accuracy of ranking individuals based on predicted merit. These are often calculated using cross-validation procedures within the simulation or by comparing simulated predictions to external validation data.  
2. **Genetic Outcomes:** This category focuses on the impact of the simulated breeding strategy on the genetic makeup and improvement of the population over time.  
   * *Metrics:*  
     * *Genetic Gain:* The rate of improvement in the mean genetic value for the target trait(s) per unit time (e.g., per year or per breeding cycle). This is often the primary metric for comparing breeding strategy efficiency.  
     * *Genetic Variance:* The amount of genetic variation remaining in the population, often tracked over cycles. Maintaining sufficient genetic variance is crucial for sustained long-term gain. Changes in additive genetic variance are particularly important.  
     * *Allele Frequencies:* Tracking the frequency changes of favorable alleles at known or simulated QTLs, or monitoring the loss of rare alleles.  
     * *Genetic Diversity/Inbreeding:* Metrics quantifying the level of diversity maintained, such as effective population size (N\_e), genome-wide heterozygosity, or the average coefficient of inbreeding (calculated from pedigree or genomic data).  
3. **Resource Efficiency and Cost:** Evaluating the simulated strategies from an economic perspective.  
   * *Metrics:* Simulated cost per unit of genetic gain achieved, total program cost over a defined period, time required to reach a specific breeding goal or release a new cultivar, efficiency of resource utilization (e.g., number of plots needed, number of individuals genotyped or phenotyped per cycle). Requires assigning costs to different breeding activities within the simulation.  
4. **Computational Performance:** Assessing the efficiency and practicality of the simulation software itself.  
   * *Metrics:* Total execution time for running a specified number of replicates and cycles, memory (RAM) usage, scalability (how runtime/memory usage increases with larger problem sizes, e.g., more individuals, markers, or environments). Important for determining the feasibility of exploring complex scenarios.  
5. **Model Fidelity/Realism:** A more qualitative assessment of how well the simulation captures the known biological processes, genetic principles, and operational realities of the target breeding system. This relates closely to the validation process (Section 7\) and involves judging whether the simulated patterns (e.g., LD decay, distribution of effects, GxE patterns) are plausible.  
6. **Usability/Utility:** Evaluating the ease with which the intended users (e.g., researchers, breeders) can set up, run, modify, and interpret the simulation and its outputs. This includes aspects like documentation clarity, user interface intuitiveness, and the effort required to adapt the simulation for new questions or scenarios.

**Benchmarking** is an important part of evaluation. This involves comparing the simulation's results against known references, such as:

* Theoretical expectations (e.g., comparing simulated genetic gain against predictions from the breeder's equation under simplified assumptions).  
* Results from previously published simulation studies using similar parameters or scenarios.  
* Outputs from alternative simulation software packages run with the same input parameters.

Clear **Reporting** of evaluation results is crucial. The chosen metrics, the methods used for their calculation, and the results (including means and measures of variation across replicates) should be presented transparently for each simulated scenario, often using tables and graphical visualizations to facilitate comparison.  
The following table outlines key evaluation metrics relevant to plant breeding simulations:  
**Table 9.1: Key Evaluation Metrics for Plant Breeding Simulations**

| Metric Category | Specific Metric | Description | Relevance to Objectives | How Measured in Simulation | Key Snippets |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Predictive Accuracy** | Correlation (Predicted vs. True/Observed BV/Pheno) | Accuracy of predicting genetic merit or performance. | Assessing GS model performance, comparing prediction methods. | Calculate correlation between simulated GEBVs/phenotypes and known true values or values in a validation set (cross-validation). |  |
|  | RMSE / MAE | Magnitude of prediction errors. | Quantifying prediction error size. | Calculate Root Mean Squared Error or Mean Absolute Error between predicted and true/observed values. |  |
| **Genetic Outcomes** | Genetic Gain per Unit Time (Year/Cycle) | Rate of improvement in mean genetic value for target trait(s). | Primary measure of breeding strategy efficiency. | Track mean true genetic value of selected individuals/population over simulated time. |  |
|  | Genetic Variance (Additive, Total) | Amount of genetic variation remaining in the population. | Assessing long-term selection potential, impact of selection/drift on variation. | Calculate variance of true genetic values within the population at different cycles. |  |
|  | Allele Frequency Change / Fixation | Tracking changes in frequencies of specific (e.g., favorable/deleterious) alleles. | Understanding selection dynamics at the gene level. | Monitor frequencies of simulated QTL alleles over time. |  |
|  | Inbreeding Coefficient (F) / Effective Pop. Size (Ne) | Quantifying loss of diversity and increase in homozygosity. | Assessing sustainability, risk of inbreeding depression, long-term potential. | Calculate F from simulated pedigrees or genomic data; estimate Ne from variance in allele frequencies or F. |  |
| **Efficiency/Cost** | Cost per Unit Genetic Gain | Economic efficiency of the breeding strategy. | Comparing strategies under budget constraints. | Assign costs to simulated activities (phenotyping, genotyping, crossing) and divide total cost by total gain. |  |
|  | Time to Cultivar Release / Goal Achievement | Speed of the breeding pipeline. | Evaluating strategies for rapid development. | Measure simulated time (years/cycles) required to reach a predefined performance threshold or complete the pipeline. |  |
| **Computational** | Execution Time | Wall-clock time required to run the simulation. | Assessing feasibility and practicality for large-scale studies or optimization. | Measure runtime for a defined number of replicates and cycles. |  |
|  | Memory Usage | Amount of RAM required by the simulation. | Determining hardware requirements. | Monitor peak memory consumption during simulation runs. |  |
|  | Scalability | How performance changes with increasing problem size (population, markers, etc.). | Understanding limitations for larger or more complex scenarios. | Run simulations with varying input sizes and measure changes in runtime/memory. |  |
| **Usability/Utility** | Ease of Use / Modification | Subjective assessment of user-friendliness, documentation quality, extensibility. | Determining adoption potential and long-term value of the tool. | User feedback, assessment of documentation, effort required for setup/modification. |  |

A key consideration during evaluation is that **multi-objective evaluation is often necessary**. Plant breeding rarely focuses on a single trait or outcome; typically, programs aim to improve multiple traits simultaneously while managing resources and maintaining long-term genetic potential. Consequently, simulations designed to inform breeding decisions must often be evaluated using multiple criteria that may conflict. For example, a strategy maximizing short-term gain for yield might do so at the expense of drastically reducing genetic diversity or incurring prohibitive costs. Evaluating such a strategy based solely on genetic gain would provide an incomplete and potentially misleading picture of its overall desirability. Therefore, the evaluation framework must explicitly consider the trade-offs between different objectives (e.g., gain vs. diversity, gain vs. cost, accuracy vs. computational time) by reporting and analyzing multiple relevant metrics simultaneously. Recognizing this need, some simulation platforms like PyBrOpS are even incorporating tools for formal multi-objective optimization directly into their framework. A comprehensive evaluation requires understanding how different strategies perform across the spectrum of relevant metrics, allowing for informed decisions based on the specific priorities and constraints of the breeding program.

## **Section 10: Plan for Documentation and Dissemination**

Comprehensive documentation and a clear dissemination strategy are not merely afterthoughts but integral components of a rigorous simulation research plan. Thorough documentation is paramount for ensuring transparency, enabling reproducibility, facilitating understanding and reuse by others (and the original developers in the future), and supporting ongoing development and maintenance of the simulation model and its associated code. A lack of clear, standardized documentation has been a significant criticism leveled against complex simulation models, hindering their evaluation and adoption.  
**Model Documentation Standards:**

* **ODD (Overview, Design concepts, Details) Protocol:** The use of the ODD protocol is strongly recommended as a standard framework for describing individual-based or agent-based models, and its principles are highly applicable to stochastic plant breeding simulations. ODD provides a structured, seven-element checklist ensuring key aspects of the model are described logically and consistently:  
  1. *Purpose:* What is the model's specific objective?  
  2. *Entities, State Variables, and Scales:* What are the components of the model (e.g., individuals, genes, plots), what characteristics define them, and what are the spatial/temporal scales?  
  3. *Process Overview and Scheduling:* What processes occur in the model (e.g., selection, recombination, growth), and in what order are they executed?  
  4. *Design Concepts:* Describes key theoretical underpinnings and modeling choices, such as emergence, adaptation, objectives (agent goals), learning, prediction, sensing, interaction, stochasticity, collectives, observation.  
  5. *Initialization:* How is the simulation world set up at the start (e.g., founder population characteristics, initial environmental state)?  
  6. *Input Data:* Does the model use input data to represent time-varying processes?  
  7. *Submodels:* Detailed description of each core process/algorithm (e.g., the specific equations for phenotype calculation, the algorithm for simulating recombination). Using ODD helps ensure completeness and makes model descriptions easier for others to understand and compare.  
* **Content and Detail:** The documentation should cover all aspects outlined in the model design plan (Section 6), explicitly stating assumptions, parameter values and their sources (use tables for clarity ), algorithms implemented, and the simulation workflow or schedule (diagrams or pseudo-code can be helpful ). The level of detail should, in principle, be sufficient to allow another researcher to reimplement the model, although achieving full replication often requires access to the original code.

**Code Documentation:**

* **Internal Comments:** Code should be generously commented to explain the purpose of different sections, the logic of algorithms, and the meaning of variables.  
* **Logical Structure:** Organize the code using functions, classes, or modules to enhance readability and maintainability.  
* **README File:** Include a comprehensive README file that explains the simulation's purpose, lists dependencies, provides instructions for installation and execution, describes input file formats, and explains how to interpret the output files.  
* **Version Control:** Utilize a version control system like Git throughout the development process. This tracks changes, facilitates collaboration, and allows specific versions of the code associated with publications or analyses to be archived and referenced.

**Data Documentation:**

* Describe the formats, units, and sources of all input data used by the simulation. Detail any data cleaning, transformation, or pre-processing steps applied.  
* Adhere to metadata standards like MIAPPE for describing associated experimental context, especially for phenotypic and environmental data.  
* Clearly define the format, content, and units of all output data files generated by the simulation.

**Dissemination Strategy:**  
A multi-pronged approach is usually needed to effectively share the simulation tool and research findings:

* **Code Sharing:**  
  * *Platforms:* Make the simulation source code publicly available through repositories like GitHub or GitLab. This fosters transparency, allows others to verify the implementation, and enables community contributions or adaptations.  
  * *Licensing:* Apply a suitable open-source license (e.g., MIT, BSD, GPL) to clearly define the terms under which others can use, modify, and distribute the code.  
* **Model Description Publication:**  
  * *Journals:* Publish a detailed description of the simulation model itself, ideally using the ODD protocol, in a relevant peer-reviewed journal. Suitable venues might include journals focused on computational biology, modeling (*in silico* Plants, Journal of Artificial Societies and Social Simulation \- JASS S), genetics (G3: Genes, Genomes, Genetics), or plant breeding (Theoretical and Applied Genetics). Journals like *Modeling Biomolecular Systems and Genetic Networks* (MBMG) specifically focus on methods and models.  
  * *Supplementary Material:* Use supplementary files to provide the full ODD documentation, links to the code repository, extensive parameter lists, or detailed algorithm descriptions that might exceed journal length limits.  
* **Research Findings Publication:** Publish the scientific results obtained from using the simulation (e.g., comparisons of breeding strategies, insights into genetic mechanisms, optimization results) in appropriate journals targeting the plant breeding, genetics, or broader agricultural science community.  
* **Conferences and Workshops:** Present the simulation tool, its validation, and key findings at relevant scientific meetings, conferences (e.g., Plant & Animal Genome Conference, society meetings for breeding or genetics), and workshops to engage with the community and solicit feedback.  
* **Data Archiving:** Deposit relevant datasets associated with the simulation study – such as input parameter files, summary output statistics across replicates, or potentially anonymized subsets of underlying empirical data used for calibration/validation (where permissible) – in public data repositories (e.g., Zenodo, Dryad, BioStudies). Follow FAIR data principles (Findable, Accessible, Interoperable, Reusable) and link datasets to publications using Digital Object Identifiers (DOIs). Data archiving is also emphasized in collaborative projects like AgMIP.

Awareness of **Emerging Standards** is also important. Initiatives like the Open Modeling Foundation (OMF) are working towards developing community-endorsed standards and best practices for computational modeling across sciences, aiming to improve model transparency, reproducibility, interoperability, and overall FAIRness. Aligning documentation and dissemination practices with such emerging standards will enhance the long-term value and impact of the simulation work.  
Engaging in structured **documentation, particularly using frameworks like ODD, should be viewed as an integral part of the model design and refinement process**, not just a final reporting step. The act of systematically describing the model's purpose, components, processes, and assumptions often forces developers to clarify their thinking and can reveal logical inconsistencies, ambiguities, or gaps in the initial design that might otherwise be overlooked. Explicitly addressing the ODD "Design Concepts" encourages rigorous consideration of the model's theoretical basis and underlying philosophy. Thus, iterative documentation throughout development can significantly improve the quality and robustness of the final simulation model.  
Furthermore, the **dissemination of the model description and, crucially, the underlying code enables broader community validation and extension**. Making the simulation accessible allows independent researchers to test its behavior, verify its findings under different conditions, identify potential bugs or limitations, and build upon the work. This open approach, facilitated by platforms like GitHub and standardized documentation, moves beyond simple reproducibility to foster a collaborative ecosystem where simulation tools can be collectively improved, adapted for new species or traits, and integrated with other models, thereby accelerating progress in the field.

## **Conclusion**

This research plan provides a comprehensive framework for the systematic development, validation, and dissemination of plant breeding simulations. It outlines ten essential steps, beginning with the critical definition of clear research objectives and proceeding through literature review, data assessment, model and software selection, detailed design planning, rigorous calibration and validation, anticipation of challenges, establishment of evaluation metrics, and finally, thorough documentation and dissemination.  
Adherence to this structured approach is crucial for creating simulation tools that are not only computationally sound but also biologically relevant and practically useful. Well-designed and validated simulations serve as powerful instruments in the modern plant breeder's toolkit. They enable the cost-effective exploration of complex breeding strategies *in silico*, facilitate the optimization of resource allocation, provide insights into the interplay of genetics and environment (GxE), help predict and accelerate genetic gain, and contribute to the training of future breeders. By bridging quantitative genetic theory with applied breeding practices, these simulations ultimately contribute to the development of improved crop varieties needed to meet global demands for food, feed, fiber, and fuel in a sustainable manner.  
The future of plant breeding simulation likely involves tighter integration with artificial intelligence and machine learning for enhanced prediction and optimization, the development of multi-scale models linking processes from the molecular level to the field scale, improved methods for incorporating and predicting responses to environmental uncertainty (particularly under climate change scenarios), and the continued evolution of user-friendly, flexible, and computationally efficient software platforms accessible to a wider range of researchers and breeders. Consistent application of rigorous design principles, validation methods, and documentation standards, as outlined in this plan, will be essential for realizing the full potential of simulation modeling in advancing plant breeding science and practice.

#### **Works cited**

1\. Optimizing the selection of quantitative traits in plant ... \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2025.1495662/full 2\. (PDF) Plant breeding simulations with AlphaSimR \- ResearchGate, https://www.researchgate.net/publication/383262189\_Plant\_breeding\_simulations\_with\_AlphaSimR 3\. Plant breeding simulations with AlphaSimR \- bioRxiv, https://www.biorxiv.org/content/10.1101/2023.12.30.573724v1.full-text 4\. A Systematic Narration of Some Key Concepts and Procedures in Plant Breeding \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2021.724517/full 5\. Understanding crop genetic diversity under modern plant breeding \- PMC \- PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC4624815/ 6\. Genomic Selection for Crop Improvement \- OAR@ICRISAT, https://oar.icrisat.org/10355/1/Genomic%20Selection%20for%20Crop%20Improvement\_%20New%20Molecular%20Breeding%20Strategies%20for%20Crop%20Improvement.pdf 7\. Accelerating Breeding Programs using Crop Simulation Models, https://blog.sathguru.com/agri-stimulus/accelerating-breeding-programs-using-crop-simulation-models/ 8\. Expanding genomic prediction in plant breeding: harnessing big data, machine learning, and advanced software \- ResearchGate, https://www.researchgate.net/publication/388531104\_Expanding\_genomic\_prediction\_in\_plant\_breeding\_harnessing\_big\_data\_machine\_learning\_and\_advanced\_software 9\. Chapter 13: Simulation Modeling – Quantitative Genetics for Plant Breeding, https://iastate.pressbooks.pub/quantitativegenetics/chapter/simulation-modeling/ 10\. Simulation Modeling, https://pbea.agron.iastate.edu/files/2021/12/Simulation-Modeling.pdf 11\. ADAM-Plant: A Software for Stochastic Simulations of Plant Breeding From Molecular to Phenotypic Level and From Simple Selection to Complex Speed Breeding Programs \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2018.01926/full 12\. (PDF) Computer Simulation in Plant Breeding \- ResearchGate, https://www.researchgate.net/publication/259497388\_Computer\_Simulation\_in\_Plant\_Breeding 13\. Chapter 3: Modeling and Data Simulation – Molecular Plant Breeding, https://iastate.pressbooks.pub/molecularplantbreeding/chapter/modeling-and-data-simulation/ 14\. Optimization of breeding program design through stochastic simulation with evolutionary algorithms | G3 Genes|Genomes \- Oxford Academic, https://academic.oup.com/g3journal/article/15/1/jkae248/7875069 15\. Optimization of breeding program design through stochastic simulation with evolutionary algorithms \- arXiv, https://arxiv.org/html/2407.17286v1 16\. A simulation-based breeding design that uses whole-genome prediction in tomato \- PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC4726135/ 17\. new methodology based on sensitivity analysis to simplify the recalibration of functional–structural plant models in new conditions | Annals of Botany | Oxford Academic, https://academic.oup.com/aob/article/122/3/397/5040132 18\. Parameter sensitivity analysis of crop growth model based on the Extended Fourier Amplitude Sensitivity Test method | Request PDF \- ResearchGate, https://www.researchgate.net/publication/259497216\_Parameter\_sensitivity\_analysis\_of\_crop\_growth\_model\_based\_on\_the\_Extended\_Fourier\_Amplitude\_Sensitivity\_Test\_method 19\. The ODD Protocol for Describing Agent-Based and Other Simulation Models, https://www.jasss.org/23/2/7.html 20\. Quantitative Genetics for Plant Breeding, https://iastate.pressbooks.pub/quantitativegenetics/back-matter/plant-breeding-basics/ 21\. Simulation Modeling in Plant Breeding: Principles and Applications \- ResearchGate, https://www.researchgate.net/publication/229352734\_Simulation\_Modeling\_in\_Plant\_Breeding\_Principles\_and\_Applications 22\. Crop/Plant Modeling Supports Plant Breeding: I. Optimization of Environmental Factors in Accelerating Crop Growth and Development for Speed Breeding \- PMC \- PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC10561689/ 23\. QU-GENE: a simulation platform for quantitative analysis of genetic ..., https://pubmed.ncbi.nlm.nih.gov/9730929/ 24\. Modelling selection response in plant breeding programs using crop models as mechanistic gene-to-phenotype (CGM-G2P) multi-trait link functions \- ResearchGate, https://www.researchgate.net/publication/348014069\_Modelling\_selection\_response\_in\_plant\_breeding\_programs\_using\_crop\_models\_as\_mechanistic\_gene-to-phenotype\_CGM-G2P\_multi-trait\_link\_functions 25\. Can Crop Models Identify Critical Gaps in Genetics, Environment, and Management Interactions? \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2020.00737/full 26\. Combining Crop Growth Modeling With Trait-Assisted Prediction Improved the Prediction of Genotype by Environment Interactions \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2020.00827/full 27\. Modeling and Data Simulation \- Plant Breeding E-Learning in Africa, https://pbea.agron.iastate.edu/files/2021/11/Molecular-Plant-Breeding.pdf 28\. Comparison of genomic-enabled cross selection criteria for the improvement of inbred line breeding populations | G3 Genes \- Oxford Academic, https://academic.oup.com/g3journal/article/13/11/jkad195/7251440 29\. Optimizing the selection of quantitative traits in plant breeding using simulation \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2025.1495662/pdf 30\. Resource Allocation for Maximizing Prediction Accuracy and Genetic Gain of Genomic Selection in Plant Breeding: A Simulation Experiment | G3 Genes \- Oxford Academic, https://academic.oup.com/g3journal/article/3/3/481/6025701 31\. Modelling selection response in plant-breeding ... \- Oxford Academic, https://academic.oup.com/insilicoplants/article-pdf/3/1/diaa016/36395090/diaa016.pdf 32\. Estimating the Contribution of Mutation, Recombination and Gene Conversion in the Generation of Haplotypic Diversity \- PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC1526701/ 33\. pSBVB: A Versatile Simulation Tool To Evaluate Genomic Selection in Polyploid Species | G3 Genes \- Oxford Academic, https://academic.oup.com/g3journal/article/9/2/327/6026705 34\. Manipulation of Meiotic Recombination to Hasten Crop Improvement \- MDPI, https://www.mdpi.com/2079-7737/11/3/369 35\. Perspective for genomic-enabled prediction against black sigatoka disease and drought stress in polyploid species \- PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC9650417/ 36\. Quantitative Genetics for Plant Breeding – Simple Book Publishing, https://iastate.pressbooks.pub/quantitativegenetics/ 37\. Incorporating gene expression and environment for genomic prediction in wheat \- bioRxiv, https://www.biorxiv.org/content/biorxiv/early/2024/09/27/2024.09.26.612369.full.pdf 38\. Modelling selection response in plant-breeding programs using crop models as mechanistic gene-to-phenotype (CGM-G2P) multi-trait link functions | in silico Plants | Oxford Academic, https://academic.oup.com/insilicoplants/article-abstract/3/1/diaa016/6053748 39\. Enviromics: bridging different sources of data, building one framework \- SciELO, https://www.scielo.br/j/cbab/a/3sR6xs5YrzvdgzS3Ry8TN4p/ 40\. Genome and Environment Based Prediction Models and Methods of Complex Traits Incorporating Genotype × Environment Interaction \- LSU Scholarly Repository, https://repository.lsu.edu/cgi/viewcontent.cgi?article=1280\&context=plantsoil\_pubs 41\. What's the use of multi-response models in plant/animal breeding? \- ResearchGate, https://www.researchgate.net/post/Whats\_the\_use\_of\_multi-response\_models\_in\_plant\_animal\_breeding 42\. Standards for collecting and displaying phenotypic data and images DELIVERABLE 1.1 \- Grace-ri, https://www.grace-ri.eu/fileadmin/user\_upload/Pro-grace/Img/Deliverables/D1.1.pdf 43\. (PDF) Modelling selection response in plant breeding programs using crop models as mechanistic gene-to-phenotype (CGM-G2P) multi-trait link functions \- ResearchGate, https://www.researchgate.net/publication/346222994\_Modelling\_selection\_response\_in\_plant\_breeding\_programs\_using\_crop\_models\_as\_mechanistic\_gene-to-phenotype\_CGM-G2P\_multi-trait\_link\_functions 44\. Modelling selection response in plant-breeding programs using crop models as mechanistic gene-to-phenotype (CGM-G2P) mu… \- OUCI, https://ouci.dntb.gov.ua/en/works/7qoa1Lbl/ 45\. Towards improved calibration of crop models – Where are we now and where should we go? | Request PDF \- ResearchGate, https://www.researchgate.net/publication/322924950\_Towards\_improved\_calibration\_of\_crop\_models\_-\_Where\_are\_we\_now\_and\_where\_should\_we\_go 46\. Your domain: Plant sciences | RDMkit, https://rdmkit.elixir-europe.org/plant\_sciences 47\. The Modern Plant Breeding Triangle: Optimizing the Use of Genomics, Phenomics, and Enviromics Data \- PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC8085545/ 48\. Climate and genetic data enhancement using deep learning analytics to improve maize yield predictability \- Genomes to Fields, https://www.genomes2fields.org/docs/publications/erac146.pdf 49\. Model Calibration, Validation, and Verification Guidance \- Climate Action Reserve, https://climateactionreserve.org/wp-content/uploads/2020/08/SEP-Model-Cal\_Val\_Ver-Guidance-for-Public-Comment-August.pdf 50\. Harnessing Agronomics through Genomics and Phenomics in Plant Breeding: A Review \- Preprints.org, https://www.preprints.org/manuscript/202103.0519/v1/download 51\. AlphaSimR: an R package for breeding program simulations \- PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC8022926/ 52\. ChromaX: a fast and scalable breeding program simulator \- WUR eDepot, https://edepot.wur.nl/645309 53\. PyBrOpS: a Python package for breeding program simulation and optimization for multi-objective breeding \- PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC11457082/ 54\. Modeling Crop Genetic Resources Phenotyping Information Systems \- PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC6597887/ 55\. Enviromics: bridging different sources of data, building one framework \- ResearchGate, https://www.researchgate.net/publication/354062895\_Enviromics\_bridging\_different\_sources\_of\_data\_building\_one\_framework 56\. Perspectives on Applications of Hierarchical Gene-To-Phenotype (G2P) Maps to Capture Non-stationary Effects of Alleles in Genomic Prediction, https://pmc.ncbi.nlm.nih.gov/articles/PMC8211918/ 57\. (PDF) Managing Data in Breeding, Selection and in Practice: A Hundred Year Problem That Requires a Rapid Solution \- ResearchGate, https://www.researchgate.net/publication/364809006\_Managing\_Data\_in\_Breeding\_Selection\_and\_in\_Practice\_A\_Hundred\_Year\_Problem\_That\_Requires\_a\_Rapid\_Solution 58\. Next generation crop models: A modular approach to model early ..., https://pmc.ncbi.nlm.nih.gov/articles/PMC5485674/ 59\. Plant science in the age of simulation intelligence \- Frontiers, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2023.1299208/full 60\. Application of Crop Growth Models to Assist Breeding for Intercropping: Opportunities and Challenges \- PMC \- PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC8854142/ 61\. Plant Breeding in the face of climate change Carlos D Messina & Mark Cooper Horticultural Sciences Department, IFAS, Univers \- bioRxiv, https://www.biorxiv.org/content/10.1101/2022.10.07.511293v2.full.pdf 62\. Professor Mark Cooper \- Queensland Alliance for Agriculture and Food Innovation, https://qaafi.uq.edu.au/profile/4060/mark-cooper 63\. Professor Graeme Hammer \- Queensland Alliance for Agriculture and Food Innovation, https://qaafi.uq.edu.au/profile/189/graeme-hammer 64\. Modelling selection response in plant-breeding programs using crop, https://ouci.dntb.gov.ua/works/7qoa1Lbl/ 65\. An overview of agent-based models in plant biology and ecology ..., https://pmc.ncbi.nlm.nih.gov/articles/PMC7489105/ 66\. Agent-based model in biology \- Wikipedia, https://en.wikipedia.org/wiki/Agent-based\_model\_in\_biology 67\. Agent-based models in cellular systems \- Frontiers, https://www.frontiersin.org/journals/physics/articles/10.3389/fphy.2022.968409/full 68\. Agent-Based Plant Growth Modeling \- ResearchGate, https://www.researchgate.net/publication/232634089\_Agent-Based\_Plant\_Growth\_Modeling 69\. A review of agent-based modeling for simulation of agricultural systems \- Redalyc, https://www.redalyc.org/journal/496/49671281013/html/ 70\. Agent-based modeling: Methods and techniques for simulating human systems \- PNAS, https://www.pnas.org/doi/10.1073/pnas.082080899 71\. Facilitating Parameter Estimation and Sensitivity Analysis of Agent-Based Models, https://www.jasss.org/17/3/11.html 72\. Artificial intelligence meets genomic selection: comparing deep learning and GBLUP across diverse plant datasets \- Frontiers, https://www.frontiersin.org/journals/genetics/articles/10.3389/fgene.2025.1568705/full 73\. ExAutoGP: Enhancing Genomic Prediction Stability and Interpretability with Automated Machine Learning and SHAP \- PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12024354/ 74\. ExAutoGP: Enhancing Genomic Prediction Stability and Interpretability with Automated Machine Learning and SHAP \- ResearchGate, https://www.researchgate.net/publication/390964557\_ExAutoGP\_Enhancing\_Genomic\_Prediction\_Stability\_and\_Interpretability\_with\_Automated\_Machine\_Learning\_and\_SHAP 75\. Machine Learning Applied to the Search for Nonlinear Features in Breeding Populations, https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2022.876578/full 76\. An Overview of Foundation Models in Plant Breeding \- Computomics, https://www.computomics.com/news-reader/foundation-models-in-plant-breeding-an-introduction-copy.html 77\. Exploring impact of recombination landscapes on breeding outcomes \- PNAS, https://www.pnas.org/doi/10.1073/pnas.2205785119 78\. MoBPSweb: A web-based framework to simulate and compare breeding programs | G3 Genes|Genomes \- Oxford Academic, https://academic.oup.com/g3journal/article/11/2/jkab023/6128572 79\. Simulation Software in the Design and AI-Driven Automation of All-Terrain Farm Vehicles and Implements for Precision Agriculture \- lidsen, https://www.lidsen.com/journals/rpse/rpse-01-02-006 80\. Fast and Accurate Bayesian Polygenic Risk Modeling with Variational Inference | bioRxiv, https://www.biorxiv.org/content/10.1101/2022.05.10.491396v2.full-text 81\. Breeder's Equation Simulation \- AlphaSimR \- YouTube, https://m.youtube.com/watch?v=jdTuh6k\_V\_4 82\. Requirements and Guidance for Model Calibration, Validation, Uncertainty, and Verification \- Climate Action Reserve, https://climateactionreserve.org/wp-content/uploads/2020/10/SEP-Model-Requirements-and-Guidance-v1.0a.pdf 83\. SWAT: MODEL USE, CALIBRATION, AND VALIDATION, https://swat.tamu.edu/media/99051/azdezasp.pdf 84\. Model Calibration and Model Validation \- What's the Difference?, https://www.nafems.org/blog/posts/model-calibration-and-model-validation-whats-the-difference/ 85\. The ODD protocol: a review and first update \- UFZ, https://www.ufz.de/export/data/2/100066\_ODD\_Update.pdf 86\. Documenting Social Simulation Models: The ODD Protocol as a Standard \- Faculty Website Directory, https://faculty.sites.iastate.edu/tesfatsi/archive/tesfatsi/DocumentingABMODD.GrimmPolhillTouza2013.pdf 87\. The ODD protocol for describing agent-based and other simulation models: A second update to improve clarity, replication, and structural realism \- USGS Publications Warehouse, https://pubs.usgs.gov/publication/70209554 88\. How to make models more useful \- PNAS, https://www.pnas.org/doi/10.1073/pnas.2202112119 89\. (PDF) Using the ODD Protocol for Describing Three Agent-Based Social Simulation Models of Land-Use Change \- ResearchGate, https://www.researchgate.net/publication/5140544\_Using\_the\_ODD\_Protocol\_for\_Describing\_Three\_Agent-Based\_Social\_Simulation\_Models\_of\_Land-Use\_Change 90\. About \- Metabarcoding and Metagenomics \- Pensoft Publishers, https://mbmg.pensoft.net/about 91\. Protocols for AgMIP Regional Integrated Assessments, https://agmip.org/wp-content/uploads/2018/08/AgMIP-Protocols-for-Regional-Integrated-Assessment-v7-0-20180218-1-ilovepdf-compressed.pdf